{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50이용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights=None)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- resnet튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_KERAS_BACKEND = None\n",
    "_KERAS_LAYERS = None\n",
    "_KERAS_MODELS = None\n",
    "_KERAS_UTILS = None\n",
    "def get_submodules_from_kwargs(kwargs):\n",
    "    import tensorflow.keras.utils\n",
    "    import tensorflow.keras.backend as backend\n",
    "    import tensorflow.keras.layers as layers\n",
    "    import tensorflow.keras.models as models\n",
    "    backend = backend\n",
    "    layers = layers\n",
    "    models = models\n",
    "    utils = tensorflow.keras.utils\n",
    "    for key in kwargs.keys():\n",
    "        if key not in ['backend', 'layers', 'models', 'utils']:\n",
    "            raise TypeError('Invalid keyword argument: %s', key)\n",
    "    return backend, layers, models, utils\n",
    "\n",
    "def decode_predictions(preds, top=5, **kwargs):\n",
    "    \"\"\"Decodes the prediction of an ImageNet model.\n",
    "    # Arguments\n",
    "        preds: Numpy tensor encoding a batch of predictions.\n",
    "        top: Integer, how many top-guesses to return.\n",
    "    # Returns\n",
    "        A list of lists of top class prediction tuples\n",
    "        `(class_name, class_description, score)`.\n",
    "        One list of tuples per sample in batch input.\n",
    "    # Raises\n",
    "        ValueError: In case of invalid shape of the `pred` array\n",
    "            (must be 2D).\n",
    "    \"\"\"\n",
    "    global CLASS_INDEX\n",
    "\n",
    "    backend, _, _, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n",
    "        raise ValueError('`decode_predictions` expects '\n",
    "                         'a batch of predictions '\n",
    "                         '(i.e. a 2D array of shape (samples, 1000)). '\n",
    "                         'Found array with shape: ' + str(preds.shape))\n",
    "    if CLASS_INDEX is None:\n",
    "        fpath = keras_utils.get_file(\n",
    "            'imagenet_class_index.json',\n",
    "            CLASS_INDEX_PATH,\n",
    "            cache_subdir='models',\n",
    "            file_hash='c2c37ea517e94d9795004a39431a14cb')\n",
    "        with open(fpath) as f:\n",
    "            CLASS_INDEX = json.load(f)\n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n",
    "        result.sort(key=lambda x: x[2], reverse=True)\n",
    "        results.append(result)\n",
    "    return results\n",
    "def _obtain_input_shape(input_shape,\n",
    "                        default_size,\n",
    "                        min_size,\n",
    "                        data_format,\n",
    "                        require_flatten,\n",
    "                        weights=None):\n",
    "    \"\"\"Internal utility to compute/validate a model's input shape.\n",
    "    # Arguments\n",
    "        input_shape: Either None (will return the default network input shape),\n",
    "            or a user-provided shape to be validated.\n",
    "        default_size: Default input width/height for the model.\n",
    "        min_size: Minimum input width/height accepted by the model.\n",
    "        data_format: Image data format to use.\n",
    "        require_flatten: Whether the model is expected to\n",
    "            be linked to a classifier via a Flatten layer.\n",
    "        weights: One of `None` (random initialization)\n",
    "            or 'imagenet' (pre-training on ImageNet).\n",
    "            If weights='imagenet' input channels must be equal to 3.\n",
    "    # Returns\n",
    "        An integer shape tuple (may include None entries).\n",
    "    # Raises\n",
    "        ValueError: In case of invalid argument values.\n",
    "    \"\"\"\n",
    "    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape[0] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with ' +\n",
    "                    str(input_shape[0]) + ' input channels.')\n",
    "            default_shape = (input_shape[0], default_size, default_size)\n",
    "        else:\n",
    "            if input_shape[-1] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with ' +\n",
    "                    str(input_shape[-1]) + ' input channels.')\n",
    "            default_shape = (default_size, default_size, input_shape[-1])\n",
    "    else:\n",
    "        if data_format == 'channels_first':\n",
    "            default_shape = (3, default_size, default_size)\n",
    "        else:\n",
    "            default_shape = (default_size, default_size, 3)\n",
    "    if weights == 'imagenet' and require_flatten:\n",
    "        if input_shape is not None:\n",
    "            if input_shape != default_shape:\n",
    "                raise ValueError('When setting `include_top=True` '\n",
    "                                 'and loading `imagenet` weights, '\n",
    "                                 '`input_shape` should be ' +\n",
    "                                 str(default_shape) + '.')\n",
    "        return default_shape\n",
    "    if input_shape:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 3:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of three integers.')\n",
    "                if input_shape[0] != 3 and weights == 'imagenet':\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n",
    "                   (input_shape[2] is not None and input_shape[2] < min_size)):\n",
    "                    raise ValueError('Input size must be at least ' +\n",
    "                                     str(min_size) + 'x' + str(min_size) +\n",
    "                                     '; got `input_shape=' +\n",
    "                                     str(input_shape) + '`')\n",
    "        else:\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 3:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of three integers.')\n",
    "                if input_shape[-1] != 3 and weights == 'imagenet':\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n",
    "                   (input_shape[1] is not None and input_shape[1] < min_size)):\n",
    "                    raise ValueError('Input size must be at least ' +\n",
    "                                     str(min_size) + 'x' + str(min_size) +\n",
    "                                     '; got `input_shape=' +\n",
    "                                     str(input_shape) + '`')\n",
    "    else:\n",
    "        if require_flatten:\n",
    "            input_shape = default_shape\n",
    "        else:\n",
    "            if data_format == 'channels_first':\n",
    "                input_shape = (3, None, None)\n",
    "            else:\n",
    "                input_shape = (None, None, 3)\n",
    "    if require_flatten:\n",
    "        if None in input_shape:\n",
    "            raise ValueError('If `include_top` is True, '\n",
    "                             'you should specify a static `input_shape`. '\n",
    "                             'Got `input_shape=' + str(input_shape) + '`')\n",
    "    return input_shape\n",
    "def preprocess_input(x, **kwargs):\n",
    "    \"\"\"Preprocesses a numpy array encoding a batch of images.\n",
    "    # Arguments\n",
    "        x: a 4D numpy array consists of RGB values within [0, 255].\n",
    "        data_format: data format of the image tensor.\n",
    "    # Returns\n",
    "        Preprocessed array.\n",
    "    \"\"\"\n",
    "    return imagenet_utils.preprocess_input(x, mode='caffe', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from . import get_submodules_from_kwargs\n",
    "#from . import imagenet_utils\n",
    "from. import decode_predictions\n",
    "from. import _obtain_input_shape\n",
    "\n",
    "preprocess_input = preprocess_input\n",
    "\n",
    "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
    "                'releases/download/v0.2/'\n",
    "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
    "                       'releases/download/v0.2/'\n",
    "                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "backend = None\n",
    "layers = None\n",
    "models = None\n",
    "keras_utils = None\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "   \n",
    "    filters1, filters2, filters3 = filters\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1),\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size,\n",
    "                      padding='same',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1),\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def conv_block(input_tensor,\n",
    "               kernel_size,\n",
    "               filters,\n",
    "               stage,\n",
    "               block,\n",
    "               strides=(2, 2)):\n",
    "  \n",
    "    filters1, filters2, filters3 = filters\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1), strides=strides,\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1),\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = layers.BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ResNet50(include_top=False,\n",
    "             weights=None,\n",
    "             input_tensor=None,\n",
    "             input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=2,\n",
    "             **kwargs):\n",
    "\n",
    "    global backend, layers, models, keras_utils\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `imagenet` '\n",
    "                         '(pre-training on ImageNet), '\n",
    "                         'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape=(288,432,3),\n",
    "                                      default_size=(288,432,3),\n",
    "                                      min_size=32,\n",
    "                                      data_format=backend.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
    "    x = layers.Conv2D(64, (7, 7),\n",
    "                      strides=(2, 2),\n",
    "                      padding='valid',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name='conv1')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    if include_top:\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D()(x)\n",
    "        else:\n",
    "            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
    "                          'has been changed since Keras 2.2.0.')\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name='resnet50')\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = keras_utils.get_file(\n",
    "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
    "        else:\n",
    "            weights_path = keras_utils.get_file(\n",
    "                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='a268eb855778b3df3c7506639542a6af')\n",
    "        model.load_weights(weights_path)\n",
    "        if backend.backend() == 'theano':\n",
    "            keras_utils.convert_all_kernels_in_model(model)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 288, 432, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 294, 438, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 144, 216, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 144, 216, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 144, 216, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 146, 218, 64) 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 72, 108, 64)  0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 72, 108, 64)  4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 72, 108, 64)  256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 108, 64)  0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 72, 108, 64)  36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 72, 108, 64)  256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 108, 64)  0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 72, 108, 256) 16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 72, 108, 256) 16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 72, 108, 256) 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 72, 108, 256) 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 72, 108, 256) 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 72, 108, 256) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 72, 108, 64)  16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 72, 108, 64)  256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 72, 108, 64)  0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 72, 108, 64)  36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 72, 108, 64)  256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 72, 108, 64)  0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 72, 108, 256) 16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 72, 108, 256) 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 72, 108, 256) 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 72, 108, 256) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 72, 108, 64)  16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 72, 108, 64)  256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 72, 108, 64)  0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 72, 108, 64)  36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 72, 108, 64)  256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 72, 108, 64)  0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 72, 108, 256) 16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 72, 108, 256) 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 72, 108, 256) 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 72, 108, 256) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 36, 54, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 36, 54, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 36, 54, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 36, 54, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 36, 54, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 36, 54, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 36, 54, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 36, 54, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 36, 54, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 36, 54, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 36, 54, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 36, 54, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 36, 54, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 36, 54, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 36, 54, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 36, 54, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 36, 54, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 36, 54, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 36, 54, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 36, 54, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 36, 54, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 36, 54, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 36, 54, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 36, 54, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 36, 54, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 36, 54, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 36, 54, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 36, 54, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 36, 54, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 36, 54, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 36, 54, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 36, 54, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 36, 54, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 36, 54, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 36, 54, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 36, 54, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 36, 54, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 36, 54, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 36, 54, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 36, 54, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 36, 54, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 36, 54, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 18, 27, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 18, 27, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 18, 27, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 18, 27, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 18, 27, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 18, 27, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 18, 27, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 18, 27, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 18, 27, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 18, 27, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 18, 27, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 18, 27, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 18, 27, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 18, 27, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 18, 27, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 18, 27, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 18, 27, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 18, 27, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 18, 27, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 18, 27, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 18, 27, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 18, 27, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 18, 27, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 18, 27, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 18, 27, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 18, 27, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 18, 27, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 18, 27, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 18, 27, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 18, 27, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 18, 27, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 18, 27, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 18, 27, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 18, 27, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 18, 27, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 18, 27, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 18, 27, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 18, 27, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 18, 27, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 18, 27, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 18, 27, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 18, 27, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 18, 27, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 18, 27, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 18, 27, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 18, 27, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 18, 27, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 18, 27, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 18, 27, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 18, 27, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 18, 27, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 18, 27, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 18, 27, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 18, 27, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 18, 27, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 18, 27, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 18, 27, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 18, 27, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 18, 27, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 18, 27, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 18, 27, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 18, 27, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 9, 14, 512)   524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 9, 14, 512)   2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 9, 14, 512)   0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 9, 14, 512)   2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 9, 14, 512)   2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 9, 14, 512)   0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 9, 14, 2048)  1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 9, 14, 2048)  2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 9, 14, 2048)  8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 9, 14, 2048)  8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 9, 14, 2048)  0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 9, 14, 2048)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 9, 14, 512)   1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 9, 14, 512)   2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 9, 14, 512)   0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 9, 14, 512)   2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 9, 14, 512)   2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 9, 14, 512)   0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 9, 14, 2048)  1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 9, 14, 2048)  8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 9, 14, 2048)  0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 9, 14, 2048)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 9, 14, 512)   1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 9, 14, 512)   2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 9, 14, 512)   0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 9, 14, 512)   2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 9, 14, 512)   2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 9, 14, 512)   0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 9, 14, 2048)  1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 9, 14, 2048)  8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 9, 14, 2048)  0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 9, 14, 2048)  0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2049        global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 23,536,641\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysk00\\Anaconda3\\envs\\cuda\\lib\\site-packages\\ipykernel_launcher.py:194: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Activation\n",
    "#base_model=ResNet50(input_shape=(288,432,3))\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# x = GlobalAveragePooling2D()(base_model.output) #풀링레이어추가\n",
    "# # x=layers.Dense(2048,kernel_initializer='he_normal')(x)\n",
    "# # x=layers.Dense(1024,kernel_initializer='he_normal')(x)\n",
    "# # x=layers.Dense(512,kernel_initializer='he_normal')(x)\n",
    "# pred = Dense(1, activation='sigmoid')(x)#출력class 1개로 출력레이어추가.\n",
    "# model = Model(inputs=base_model.input, outputs=pred)\n",
    "# model.compile(optimizer=SGD(lr=1e-2, decay=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model = ResNet50(input_shape=(288,432,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  split\n",
      "==============================================ResNet50==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysk00\\Anaconda3\\envs\\cuda\\lib\\site-packages\\ipykernel_launcher.py:194: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7425 images belonging to 2 classes.\n",
      "Found 1834 images belonging to 2 classes.\n",
      "train shape : (7425,)\n",
      "Epoch 1/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.6724 - accuracy: 0.5819\n",
      "Epoch 00001: val_loss improved from inf to 0.97182, saving model to .\\result_voice\\split-01-0.9718.hdf5\n",
      "1857/1857 [==============================] - 882s 475ms/step - loss: 0.6724 - accuracy: 0.5817 - val_loss: 0.9718 - val_accuracy: 0.4875\n",
      "Epoch 2/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.6417 - accuracy: 0.6335\n",
      "Epoch 00002: val_loss improved from 0.97182 to 0.78011, saving model to .\\result_voice\\split-02-0.7801.hdf5\n",
      "1857/1857 [==============================] - 872s 470ms/step - loss: 0.6418 - accuracy: 0.6334 - val_loss: 0.7801 - val_accuracy: 0.5322\n",
      "Epoch 3/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.5997 - accuracy: 0.6700\n",
      "Epoch 00003: val_loss did not improve from 0.78011\n",
      "1857/1857 [==============================] - 869s 468ms/step - loss: 0.5999 - accuracy: 0.6699 - val_loss: 1.0989 - val_accuracy: 0.5453\n",
      "Epoch 4/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.5587 - accuracy: 0.7137\n",
      "Epoch 00004: val_loss improved from 0.78011 to 0.56559, saving model to .\\result_voice\\split-04-0.5656.hdf5\n",
      "1857/1857 [==============================] - 872s 470ms/step - loss: 0.5586 - accuracy: 0.7138 - val_loss: 0.5656 - val_accuracy: 0.6936\n",
      "Epoch 5/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.5291 - accuracy: 0.7348\n",
      "Epoch 00005: val_loss improved from 0.56559 to 0.54934, saving model to .\\result_voice\\split-05-0.5493.hdf5\n",
      "1857/1857 [==============================] - 869s 468ms/step - loss: 0.5290 - accuracy: 0.7349 - val_loss: 0.5493 - val_accuracy: 0.7328\n",
      "Epoch 6/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.5172 - accuracy: 0.7459\n",
      "Epoch 00006: val_loss did not improve from 0.54934\n",
      "1857/1857 [==============================] - 877s 472ms/step - loss: 0.5175 - accuracy: 0.7456 - val_loss: 0.8980 - val_accuracy: 0.5616\n",
      "Epoch 7/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.4867 - accuracy: 0.7704\n",
      "Epoch 00007: val_loss did not improve from 0.54934\n",
      "1857/1857 [==============================] - 868s 467ms/step - loss: 0.4866 - accuracy: 0.7704 - val_loss: 0.5612 - val_accuracy: 0.7459\n",
      "Epoch 8/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.4602 - accuracy: 0.7816\n",
      "Epoch 00008: val_loss did not improve from 0.54934\n",
      "1857/1857 [==============================] - 869s 468ms/step - loss: 0.4602 - accuracy: 0.7815 - val_loss: 0.6445 - val_accuracy: 0.6739\n",
      "Epoch 9/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.4460 - accuracy: 0.7965\n",
      "Epoch 00009: val_loss improved from 0.54934 to 0.46343, saving model to .\\result_voice\\split-09-0.4634.hdf5\n",
      "1857/1857 [==============================] - 869s 468ms/step - loss: 0.4460 - accuracy: 0.7966 - val_loss: 0.4634 - val_accuracy: 0.7808\n",
      "Epoch 10/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.4193 - accuracy: 0.8061\n",
      "Epoch 00010: val_loss did not improve from 0.46343\n",
      "1857/1857 [==============================] - 866s 466ms/step - loss: 0.4192 - accuracy: 0.8062 - val_loss: 0.5559 - val_accuracy: 0.7345\n",
      "Epoch 11/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.3985 - accuracy: 0.8232\n",
      "Epoch 00011: val_loss did not improve from 0.46343\n",
      "1857/1857 [==============================] - 866s 466ms/step - loss: 0.3985 - accuracy: 0.8233 - val_loss: 0.4700 - val_accuracy: 0.7841\n",
      "Epoch 12/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.3632 - accuracy: 0.8414\n",
      "Epoch 00012: val_loss did not improve from 0.46343\n",
      "1857/1857 [==============================] - 867s 467ms/step - loss: 0.3631 - accuracy: 0.8415 - val_loss: 0.4840 - val_accuracy: 0.7819\n",
      "Epoch 13/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.3324 - accuracy: 0.8522\n",
      "Epoch 00013: val_loss did not improve from 0.46343\n",
      "1857/1857 [==============================] - 868s 467ms/step - loss: 0.3323 - accuracy: 0.8523 - val_loss: 0.4651 - val_accuracy: 0.7966\n",
      "Epoch 14/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.3182 - accuracy: 0.8670\n",
      "Epoch 00014: val_loss did not improve from 0.46343\n",
      "1857/1857 [==============================] - 877s 472ms/step - loss: 0.3181 - accuracy: 0.8671 - val_loss: 0.5370 - val_accuracy: 0.7661\n",
      "Epoch 15/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.2941 - accuracy: 0.8762\n",
      "Epoch 00015: val_loss improved from 0.46343 to 0.46262, saving model to .\\result_voice\\split-15-0.4626.hdf5\n",
      "1857/1857 [==============================] - 868s 467ms/step - loss: 0.2941 - accuracy: 0.8761 - val_loss: 0.4626 - val_accuracy: 0.8026\n",
      "Epoch 16/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.8913\n",
      "Epoch 00016: val_loss did not improve from 0.46262\n",
      "1857/1857 [==============================] - 868s 467ms/step - loss: 0.2669 - accuracy: 0.8913 - val_loss: 0.8339 - val_accuracy: 0.6876\n",
      "Epoch 17/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.2323 - accuracy: 0.9028\n",
      "Epoch 00017: val_loss did not improve from 0.46262\n",
      "1857/1857 [==============================] - 868s 467ms/step - loss: 0.2322 - accuracy: 0.9029 - val_loss: 0.4726 - val_accuracy: 0.8026\n",
      "Epoch 18/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.2229 - accuracy: 0.9115\n",
      "Epoch 00018: val_loss did not improve from 0.46262\n",
      "1857/1857 [==============================] - 867s 467ms/step - loss: 0.2228 - accuracy: 0.9115 - val_loss: 1.2437 - val_accuracy: 0.6347\n",
      "Epoch 19/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.1960 - accuracy: 0.9216\n",
      "Epoch 00019: val_loss did not improve from 0.46262\n",
      "1857/1857 [==============================] - 868s 467ms/step - loss: 0.1960 - accuracy: 0.9216 - val_loss: 0.5205 - val_accuracy: 0.7863\n",
      "Epoch 20/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.1771 - accuracy: 0.9328\n",
      "Epoch 00020: val_loss did not improve from 0.46262\n",
      "1857/1857 [==============================] - 868s 467ms/step - loss: 0.1771 - accuracy: 0.9328 - val_loss: 0.5193 - val_accuracy: 0.7972\n",
      "Epoch 21/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.1637 - accuracy: 0.9376\n",
      "Epoch 00021: val_loss did not improve from 0.46262\n",
      "1857/1857 [==============================] - 869s 468ms/step - loss: 0.1636 - accuracy: 0.9376 - val_loss: 0.8733 - val_accuracy: 0.6848\n",
      "Epoch 22/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.1391 - accuracy: 0.9481\n",
      "Epoch 00022: val_loss did not improve from 0.46262\n",
      "1857/1857 [==============================] - 877s 472ms/step - loss: 0.1391 - accuracy: 0.9481 - val_loss: 1.0756 - val_accuracy: 0.7034\n",
      "Epoch 23/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.1410 - accuracy: 0.9469\n",
      "Epoch 00023: val_loss did not improve from 0.46262\n",
      "1857/1857 [==============================] - 868s 468ms/step - loss: 0.1409 - accuracy: 0.9469 - val_loss: 0.7759 - val_accuracy: 0.7557\n",
      "Epoch 24/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.1219 - accuracy: 0.9569\n",
      "Epoch 00024: val_loss did not improve from 0.46262\n",
      "1857/1857 [==============================] - 869s 468ms/step - loss: 0.1218 - accuracy: 0.9569 - val_loss: 0.5569 - val_accuracy: 0.7972\n",
      "Epoch 25/50\n",
      "1856/1857 [============================>.] - ETA: 0s - loss: 0.1098 - accuracy: 0.9590\n",
      "Epoch 00025: val_loss did not improve from 0.46262\n",
      "1857/1857 [==============================] - 869s 468ms/step - loss: 0.1097 - accuracy: 0.9591 - val_loss: 0.5894 - val_accuracy: 0.7732\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8026\tloss: 0.4626\n",
      "===========================================split finished===========================================\n"
     ]
    }
   ],
   "source": [
    "#### import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "%matplotlib inline\n",
    "SEED = 777\n",
    "\n",
    "def main():\n",
    "    #inputSize = 224\n",
    "    batchSize = 4\n",
    "    nEpoch = 50\n",
    "    \n",
    "    # 디렉토리 정보 설정\n",
    "    # dataDir = 'D:\\\\Face_Database\\\\B-Database'\n",
    "    dataDir = 'C:\\\\Users\\\\ysk00'   \n",
    "    # 학습 및 테스트 할 데이터베이스 디렉토리명\n",
    "    trainDB = 'split'  # D:\\Face_Database\\B-Database\\protocol_4\\train\n",
    "    validDB = 'split'\n",
    "    \n",
    "    saveDir =  '.\\\\result_voice'\n",
    "    if not os.path.exists(saveDir):    \n",
    "        os.makedirs(saveDir)\n",
    "    model_path = os.path.join(saveDir, trainDB + '-{epoch:02d}-{val_loss:.4f}.hdf5')\n",
    "    \n",
    "    # 데이터베이스별 학습 수행\n",
    "    print('>> ', trainDB)\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    print('ResNet50'.center(100, '='))\n",
    "   \n",
    "    '''\n",
    "    training\n",
    "    '''\n",
    "    K.clear_session()\n",
    "\n",
    "    # 네트워크 정의\n",
    "    model = ResNet50(input_shape=(288,432,3))\n",
    "\n",
    "    # 데이터 generator 생성\n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "                                       horizontal_flip=True,)#이미지augmentation > 이미지를 회전,확대,축소 등 여러변형해보는것.\n",
    "    train_generator = train_datagen.flow_from_directory(os.path.join(*[dataDir,trainDB,'train']),\n",
    "                                                        target_size=(288,432),\n",
    "                                                        batch_size=batchSize,\n",
    "                                                        class_mode='binary',\n",
    "                                                        interpolation='bilinear',\n",
    "                                                        shuffle=True,)\n",
    "\n",
    "    valid_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    valid_generator = valid_datagen.flow_from_directory(os.path.join(*[dataDir, validDB,'val']),\n",
    "                                                        target_size=(288,432),\n",
    "                                                        batch_size=batchSize,\n",
    "                                                        class_mode='binary',\n",
    "                                                        interpolation='bilinear',\n",
    "                                                        shuffle=False,)\n",
    "\n",
    "    print('train shape :',train_generator.classes.shape)\n",
    "    # unbalanced class를 해결하기 위한 class_weight 설정 #np.unique는 중복원소제거하는거\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes) \n",
    "\n",
    "    # callback 함수 정의 dropout함수\n",
    "    early_stop = EarlyStopping(patience=10, monitor='val_loss')\n",
    "    cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    step_num=len(train_generator)/batchSize\n",
    "\n",
    "    # 모델 학습\n",
    "    hist = model.fit_generator(train_generator, \n",
    "                               epochs=nEpoch,\n",
    "                               steps_per_epoch=len(train_generator),\n",
    "                               class_weight=class_weights,\n",
    "                               validation_data=valid_generator,\n",
    "                               validation_steps=len(valid_generator),\n",
    "                               verbose=1,\n",
    "                               callbacks=[early_stop, cb_checkpoint])\n",
    "\n",
    "    \n",
    "    # 학습 결과 그래프 그리기\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, loss_ax = plt.subplots()\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'b', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], '--r', label='val loss')\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "    print('acc: {:.4f}\\tloss: {:.4f}'.format(hist.history['val_accuracy'][-11], hist.history['val_loss'][-11]))\n",
    "\n",
    "    print(('{} finished'.format(trainDB)).center(100,'='))\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c07528aec142>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_generator' is not defined"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "    print(\"-- Evaluate --\")\n",
    "    scores = model.evaluate_generator(test_generator, steps=5)\n",
    "    print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> model loaded: split-11-0.4889.hdf5\n",
      ">>>> evaluating on 'split'\n",
      "Found 1834 images belonging to 2 classes.\n",
      "Found 2317 images belonging to 2 classes.\n",
      "-- Evaluate --\n",
      "accuracy: 85.00%\n",
      "                  pred_fake(0)   pred_real(1)\n",
      "actural_fake(0)             893            215\n",
      "actual_real(1)             236            973\n",
      "\n",
      "EER: 0.2203\tHTER: 0.1946\n",
      ">> finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습된 모델 테스트셋에서 성능 평가\n",
    "# 얼굴 스푸핑 분야에서 평가 metric으로 HTER이랑 EER 두 개 주로 사용\n",
    "# =========================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def main():\n",
    "    #inputSize = 224\n",
    "    batchSize = 4\n",
    "    \n",
    "    trainDB = 'split'\n",
    "    testDB = 'split'\n",
    "    \n",
    "    dataDir = 'C:\\\\Users\\\\ysk00'\n",
    "    modelPath = 'C:\\\\Users\\\\ysk00\\\\result_voice\\\\split-11-0.4889.hdf5'\n",
    "    \n",
    "    print('>> model loaded: {}'.format(os.path.basename(modelPath)))\n",
    "    K.clear_session()\n",
    "    model = load_model(modelPath)\n",
    "        \n",
    "    print(\">>>> evaluating on '{}'\".format(testDB))\n",
    "    test_datagen = ImageDataGenerator()\n",
    "\n",
    "    val_datagen = ImageDataGenerator()\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    val_generator = val_datagen.flow_from_directory(os.path.join(*[dataDir, testDB, 'val']),\n",
    "                                                      target_size=(288,432),\n",
    "                                                      batch_size=batchSize,\n",
    "                                                      class_mode='binary',\n",
    "                                                      interpolation='bilinear',\n",
    "                                                      shuffle=False,)\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    test_generator = test_datagen.flow_from_directory(os.path.join(*[dataDir, testDB, 'test']),\n",
    "                                                      target_size=(288,432),\n",
    "                                                      batch_size=batchSize,\n",
    "                                                      class_mode='binary',\n",
    "                                                      interpolation='bilinear',\n",
    "                                                      shuffle=False,)\n",
    "\n",
    "    ''' evaluating EER '''\n",
    "    y_true = val_generator.classes\n",
    "    y_score = model.predict_generator(val_generator, steps=len(val_generator)).ravel()\n",
    "\n",
    "    \n",
    "    fpr, tpr, threshold = roc_curve(y_true, y_score)\n",
    "    fnr = 1 - tpr\n",
    "    eer_threshold = threshold[np.nanargmin(np.absolute((fnr-fpr)))]\n",
    "    val_eer = (fpr[np.nanargmin(np.absolute((fnr - fpr)))] + fnr[np.nanargmin(np.absolute((fnr - fpr)))]) / 2\n",
    "\n",
    "    ''' evaluating HTER '''\n",
    "    y_true = test_generator.classes\n",
    "    y_score = model.predict_generator(test_generator, steps = len(test_generator)).ravel()\n",
    "\n",
    "    # Calculate EER threshold\n",
    "    fpr, tpr, threshold = roc_curve(y_true, y_score)\n",
    "    fnr = 1 - tpr\n",
    "    eer_threshold = threshold[np.nanargmin(np.absolute((fnr-fpr)))]\n",
    "    \n",
    "    #evaluation\n",
    "    print(\"-- Evaluate --\")\n",
    "    scores = model.evaluate_generator(test_generator, steps=5)\n",
    "    print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    # HTER\n",
    "    y_pred = y_score > eer_threshold\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    labels = test_generator.class_indices\n",
    "    print('                  pred_fake({})   pred_real({})\\nactural_fake({})    {:12d}   {:12d}\\nactual_real({})    {:12d}   {:12d}\\n'.format(labels['0'], labels['1'], labels['0'], tn, fp, labels['1'], fn, tp))\n",
    "    hter = (fp/(tn+fp) + fn/(fn+tp)) * 0.5\n",
    "\n",
    "    # ROC curve\n",
    "    Accuracy = ((tn+tp) / (tn+fp+fn+tp)) * 100.0\n",
    "\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "\n",
    "    plt.plot(fpr, tpr, 'r--', label='ROC_curve (acc_1st = %0.2f%%)' % Accuracy)\n",
    "    plt.plot([0, 1], [0, 1], color = 'orange', lw=lw, linestyle='--')\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "\n",
    "    plt.savefig('protocol_4_001.png')\n",
    "    plt.figure()\n",
    "    \n",
    "    print('EER: {:.4f}\\tHTER: {:.4f}'.format(val_eer, hter))\n",
    "\n",
    "    print('>> finished')\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet18"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spoofing",
   "language": "python",
   "name": "spoofing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
